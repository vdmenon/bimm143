---
title: "class9"
author: "Vaibhav Menon"
date: "5/1/2018"
output: 
  html_document: 
    keep_md: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
wisc.df <- read.csv("https://bioboot.github.io/bimm143_W18/class-material/WisconsinCancer.csv")
wisc.df

# Convert the features of the data: wisc.data
#wisc.data <- as.matrix(wisc.df,ncol= 3:32 )
```
```{r}
# Remove columns
wisc.data=as.matrix(wisc.df[,3:ncol (wisc.df)])
#wisc.data
# Set the row names of wisc.data
row.names(wisc.data) <- wisc.df$id
#head(wisc.data)
```
How many M's do we have
```{r}
table(wisc.df$diagnosis)
diagnosis <- as.numeric( wisc.df$diagnosis=="M")
diagnosis
```
```{r}
#q1 
dim(wisc.data) #wisc.data has 569 observations
#q2
length(grep("_mean", colnames(wisc.data), value=TRUE))
#q3
sum(diagnosis) #212 have a malignant diagnosis
```

```{r}
#Section 2
print("Column mean data")
colMeans(wisc.data)
print("Column Standard deviations")
apply(wisc.data,2,sd)
```
```{r}
# Perform PCA on wisc.data by completing the following code
  #Exclude column X with NAs from PCA function call
wisc.pr <- prcomp(wisc.data[,1:ncol(wisc.data)-1], scale=TRUE)
summary(wisc.pr)
```
Q4: .4427 of the variance is captured by PC1
Q5: 3 principal components are required to describe at least 70% of the original variance in the data
Q6: 7 principal components are requried to describe at least 90% of the original variance in the data
```{r}
biplot(wisc.pr)
```
The plot is practically impossible to read because everything is clustered around each other.
```{r}
#Scatter plot observations by components 1 and 2
plot(wisc.pr$x[,c(1,2)], col=(diagnosis+1), xlab="PC1", ylab="PC2")

#Scatter plot observations by components 1 and 2
plot(wisc.pr$x[,c(1,3)], col=(diagnosis+1), xlab="PC3", ylab="PC3")

# Alternative scree plot of the same data, note data driven y-axis
barplot(pve, ylab = "Precent of Variance Explained",
     names.arg=paste0("PC",1:length(pve)), las=2, axes = FALSE)
axis(2, at=pve, labels=round(pve,2)*100 )


```
##Variance explained: Scree-plot
```{r}
#calculate variance of each component
pr.var <- wisc.pr$sdev^2
head(pr.var)
pve <- pr.var/ sum(pr.var)
```

```{r}
# Plot proportion and cumulative proportion of variance explained

plot(pve, xlab = "Principal Component", 
     ylab = "Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
plot(cumsum(pve), xlab = "Principal Component", 
     ylab = "Cumulative Proportion of Variance Explained", 
     ylim = c(0, 1), type = "o")
```
Hierarchical clustering
```{r}
#scale the wsic.data data: data.scaled
data.scaled <- scale(wisc.data[,1:30])
#data.scaled
data.dist <- (dist(data.scaled))
#clustering by hclust()
wisc.hclust <- hclust(data.dist)

#Separate into groups
wisc.hclust.clusters <-cutree(wisc.hclust,k=4)
```

Plot our hclust model tree
```{r}
table(wisc.hclust.clusters, diagnosis)
```
Section 4
```{r}
wisc.km <- kmeans(data.scaled, centers=2, nstart=20)
table(wisc.km$cluster, diagnosis)
```

Compare kmeans with hclust
```{r}
table(wisc.hclust.clusters, wisc.km$cluster)
```

Section 5
```{r}
## Use the distance along the first 7 PCs for clustering i.e. wisc.pr$x[, 1:7]
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:7]), method="complete")

#Cut this hierarchical clustering model into 4 clusters and assign the results to wisc.pr.hclust.clusters.
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust, k=4)
table(wisc.pr.hclust.clusters, diagnosis)
```

